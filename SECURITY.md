# Security & Ethical Use Policy

## Intended Use

This project is provided strictly for **educational and research purposes only**. It was developed to explore the vulnerabilities and limitations of large language models (LLMs), particularly regarding their ability to resist adversarial manipulation.

## Disclaimer

- This repository may contain examples of prompts or outputs that simulate illegal or unethical content. These examples are included **solely to demonstrate model behavior** under adversarial conditions.
- **Under no circumstances** should any of the outputs or code be used to generate, distribute, or enable illegal or harmful activities.
- The author **does not condone, endorse, or accept any responsibility** for misuse of this content.
- **Any misuse of the code or methodology is strictly the responsibility of the user.**

By accessing or using this project, you agree to use it **only for lawful, academic, and ethical research**.

## Reporting Misuse or Vulnerabilities

If you identify any potential misuse, abuse pathways, or vulnerabilities:
- Please report them immediately via GitHub Issues or directly to the repository maintainer.
- Responsible disclosures will be acknowledged.
- This project does not issue security updates, but identified misuse will lead to action (including repo updates, restrictions, or takedowns if necessary).
